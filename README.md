# Hand-language Translator
미디어파이프(mediapipe)를 이용한 수화 해석 알고리즘


## 1) dataset 수집


데이터의 수집은 다음과 같이 이루어진다.
	- 손 landmark의 3차원 좌표: 21개 x3
	- 각 동작을 구분하기 위한 라벨: 1개
  
  구어체와 문어체에서 사용 빈도가 높은 한글의 자소 19가지를 선별하여 자음 10개 및 모음 9개를 택하여 학습시켰다. 선택된 19가지의 수화동작은 아래와 같다.
  
![ghvhgvkh](https://user-images.githubusercontent.com/108911413/203528090-568f7a56-fa0b-42a3-9446-587870675a38.gif)


## 2) MediaPipe를 이용하여 손가락의 움직임 인식


![hand_landmarks](https://user-images.githubusercontent.com/108911413/203527185-404056b5-4bad-4139-ab6a-bc1f4aa8d316.png)

- 0번 landmark의 좌표를 (0, 0, 0)으로 맞춘다.
- 0번과 5번을 이은 벡터를 미리 정한 기준 벡터의 방향과 크기로 변환해준다.

벡터 변환은 3D 벡터 회전 변환 행렬을 이용한다. 변환하고자 하는 정점에 아래의 행렬을 단순하게 곱하면 연산이 완료된다. 이 과정을 통해 인식되는 손의 크기나 회전에 대하여 데이터가 추가 연산 되며 변환된 3차원 좌표의 값은 넘파이 배열의 형태로 저장한다.

![벡터변환](https://user-images.githubusercontent.com/108911413/203529089-07774ef4-5cdb-4937-96ed-7e2ab203d18a.png)


## 3) K-최근접 이웃 알고리즘(KNN)을 이용한 학습


K-최근접 이웃 알고리즘(KNN)을 이용하여 학습시킨다. 
모델을 만들지 않는 K-최근접 이웃 알고리즘을 이용하는 이유는 훈련 단계가 빠르고 수치 기반 데이터 분류 작업에서 성능이 우수하기 때문이다. 또한 학습데이터의 노이즈에 크게 영향을 받지 않고 학습데이터의 수가 충분하다면 좋은 성능을 낸다. 

k의 값을 정할 때는 교차검증을 이용하여 1~(n은 총 데이터의 개수)에서 가장 에러율이 낮은 k를 선택할 것이다. 
K-최근접 이웃 알고리즘의 성능 평가를 하기 위해서는 IOU를 사용할 예정이다.


## 4) 프레임을 통한 수화 동작을 해석


카메라가 켜져 있다면 OpenCV를 이용하여 웹캠의 영상을 한 프레임씩 읽어오게 한다. OpenCV를 통하여 프레임을 읽어오는데 코딩에서 사용할 MediaPipe와 다른 컬러시스템을 사용하므로 OpenCV의 BGR 컬러시스템에서 MediaPipe의 RGB 컬러시스템으로 변경해준다. 또한 읽어온 프레임은 좌우반전 되어 있어 이미지를 다시 좌우반전 시켜주는 과정이 필요하다.

이후 프레임의 손 landmark 21개의 x 좌표, y 좌표, z 좌표 데이터를 저장한다. 구한 21개의 손가락 관절 좌표 사이의 연산을 통해서 손가락 마디의 각도를 구한다. 이를 통해 K-최근접 이웃 알고리즘(KNN)을 이용하여 수화 동작을 판별하고 각각의 수어 동작을 해석하여 한 글자씩 영상에 띄운다.



결과는 다음과 같다.

![바람](https://user-images.githubusercontent.com/108911413/203529863-53663470-a4a5-4da0-b341-d2afdda39b40.png)
![안녕](https://user-images.githubusercontent.com/108911413/203529876-fa92bbfb-e08b-4cee-ae3e-f514c346eb2b.png)

https://user-images.githubusercontent.com/108911413/203734621-daaa619a-6b40-41c3-91ba-eb32ab5c5a80.mp4
